{
 "metadata": {
  "name": "ahassa11_pr3 (2) (2) (2) (2) (1)"
 }, 
 "name": "ahassa11_pr3 (2) (2) (2) (2) (1)", 
 "nbformat": 2, 
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown", 
     "source": "Programming Assignment #3\n="
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "name = \"Amir Hassani\"\njhed_id = \"ahassa11\"\nif name == \"Student Name\" or jhed_id == \"sname1\":\n    raise Exception( \"Change the name and/or JHED ID...preferrably to yours.\")", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 1
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "from collections import Counter\nfrom IPython.core.display import *\nfrom StringIO import StringIO\n\nm = 1.0\np = 0.001", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 2
    }, 
    {
     "cell_type": "markdown", 
     "source": "Read in data from file and shuffle the data."
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "def get_data(file_name):\n    f = open(file_name)\n    lines = f.readlines()\n    f.close()\n    data = [ line.replace( '\\n', '').split( ',') for line in lines if len(line) > 0]\n    random.shuffle( data)\n    return data", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 3
    }, 
    {
     "cell_type": "markdown", 
     "source": "Initialize the confusion matrix with all possible classification combinations."
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "def initialize_confusion_matrix( classes):\n    confusion_matrix = {}\n    for clazz1 in classes:\n        for clazz2 in classes:\n            confusion_matrix[ (clazz1, clazz2)]  = 0\n    return confusion_matrix", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 4
    }, 
    {
     "cell_type": "markdown", 
     "source": "Calculate accuracy."
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "def get_accuracy( c_m, arg2, arg3):    \n    #accuracy:  (tp + tn) / (tp + tn + fp + fn)    \n    numer = 0\n    denom = 0\n    for key in c_m.keys():\n        if key[ 0] == key[ 1]:\n            numer += c_m[ key]\n        denom += c_m[ key]\n    accuracy = float( numer) / float( denom)\n    \n    #print \"accuracy = %s\" % accuracy\n    \n    return accuracy", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 5
    }, 
    {
     "cell_type": "markdown", 
     "source": "Calculate recall."
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "def get_recall( c_m, pos, neg):\n    #recall:    tp / (tp + fn)\n    recall = float( c_m[ ( pos, pos)] )/ float((c_m[ ( pos, pos)] + c_m[ ( pos, neg)]))\n    return recall", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 6
    }, 
    {
     "cell_type": "markdown", 
     "source": "Calculate precision."
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "def get_precision( c_m, pos, neg):\n    #precision: tp / (tp + fp)\n    precision = float( c_m[ ( pos, pos)] )/ float((c_m[ ( pos, pos)] + c_m[ ( neg, pos)]))\n    return precision", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 7
    }, 
    {
     "cell_type": "markdown", 
     "source": "Calculate F-Score."
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "def get_fscore( c_m, pos, neg):\n    #f-score:   2 * (P * R) / (P + R)\n    precision = get_precision( c_m, pos, neg)\n    recall = get_recall( c_m, pos, neg)\n    fscore = ( 2.0 * precision * recall) / (precision + recall)\n    \n    #print \"precision = %s\" % precision\n    #print \"recall = %s\" % recall\n    #print \"f-score = %s\" % fscore    \n    return fscore", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 8
    }, 
    {
     "cell_type": "markdown", 
     "source": "Calculate all multi-class statistics."
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "def get_multi_class_stats(c_m, pos, neg):\n    return { \"accuracy\": get_accuracy( c_m, pos, neg)}", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 9
    }, 
    {
     "cell_type": "markdown", 
     "source": "Calculate all binary statistics."
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "def get_binary_stats(c_m, pos, neg):\n    return { \"fscore\": get_fscore( c_m, pos, neg), \"precision\": get_precision( c_m, pos, neg), \"recall\": get_recall( c_m, pos, neg) }", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 10
    }, 
    {
     "cell_type": "markdown", 
     "source": "Decision tree importance function to determine the most important feature."
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "def Importance(data):\n\n    num_rows = len( data)\n    num_cols = len( data[ 0])\n\n    data_transpose = zip( *data)\n\n    # this makes counting the groups easier\n    #e.g.\n    #              a b c d | e\n    #              k j k o | c\n    # becomes ---> (a,e) (b,e) (c,e) (d,e)\n    #              (k,c) (j,c) (k,c) (o,c)\n    data_class = [ [ (col, row[ len( row) - 1]) for col in row]  for row in data]\n    data_transpose_class = zip( *data_class)\n\n\n    #data_transpose_counts [0] = \n    #[ Counter({'x': 3656, 'f': 3152, 'k': 828, 'b': 452, 's': 32, 'c': 4}),...\n    data_transpose_counts = []\n    for i in range(0, len( data_transpose)):\n        data_transpose_counts.append( Counter( data_transpose[ i]))\n        #print data_transpose_counts\n\n    #data_transpose_class_counts [0] = \n    #[Counter({('x', 'e'): 1948, ('x', 'p'): 1708, ('f', 'e'): 1596, ('f', 'p'): 1556, ('k', 'p'): 600, ('b', 'e'): 404, \n    data_transpose_class_counts = []\n    for i in range( 0, len( data_transpose_class)):\n        data_transpose_class_counts.append( Counter( data_transpose_class[ i]))\n        #print data_transpose_class_counts\n\n    entropies = []\n    for i in range( 0, len( data_transpose_counts) -1 ):\n        entropies_group = []\n        for group in data_transpose_counts[ i].keys():\n            group_count = data_transpose_counts[ i][ group]            \n            weight = float( group_count) / float( num_rows)\n            vals = []\n            for clazz in data_transpose_counts[ -1].keys():\n                group_class_count = data_transpose_class_counts[ i][ ( group, clazz)]\n                val = float( group_class_count) / float( group_count)\n                if val  > 0:\n                    vals.append( -1 * val * math.log( val, 2))\n            entropies_group.append( -1 * weight * sum( vals))\n        entropies.append( entropies_group)\n            \n    vals = []\n    for clazz in data_transpose_counts[ -1].keys():\n        class_count = data_transpose_counts[ -1][ clazz]\n        val = float( class_count) / float( num_rows)\n        vals.append( -1 * val * math.log( val, 2))\n    entropy_class = sum( vals)\n\n    #print all_entropies\n    gain = [ entropy_class + sum( entropies_group) for entropies_group in entropies]\n    #print gain\n    return gain.index( max( gain))", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 11
    }, 
    {
     "cell_type": "markdown", 
     "source": "Decision Tree algorithm to create the decision tree."
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "def Decision_Tree_Learning( data, attributes, parent_data):\n    \n    data_transpose = zip( *data)\n    data_classes = list( set( data_transpose[ -1]))\n\n    if len( data) == 0:\n        print \"NO DATA\"\n        return 1\n    if len( data_classes) == 1:\n        #print \"CLASSIFICATION IS THE SAME\"\n        return data_classes[ 0]\n    if len( data[ 0]) == 1:\n        print \"NO ATTRIBUTES\"\n        return 1\n    else:\n        i = Importance( data)\n        groups = list( set( data_transpose[ i]))\n        tree = {}\n        new_attributes = list( attributes)\n        del new_attributes[ i]\n        for group in groups:\n            new_data = [ [ row[ col_index] for col_index in range(0, len( row)) if col_index != i  ] for row in data if row[ i] == group ]\n            sub_tree = Decision_Tree_Learning( new_data, new_attributes, parent_data)\n            tree[group] = sub_tree\n            \n        return ( attributes[ i], tree)", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 12
    }, 
    {
     "cell_type": "markdown", 
     "source": "Decision tree function to manage creating the model and running the validation set against it."
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "def Decision_Tree_Learning_Train_Validation( training, validation, confusion_matrix, classes):\n    \n    attributes = [ i for i in range( 0, len( training[0 ])) ]\n\n    #print attributes\n    tree = Decision_Tree_Learning( training, attributes, training)\n    #print tree\n \n    for i in range( 1, len( validation)):\n        actual = validation[ i][ -1]\n        node = tree\n        while True:        \n            if len( node) == 2:\n                col = node[ 0]\n                val = node[ 1]\n                if validation[ i][ col] in val:\n                    node = val[ validation[ i][ col]]\n                else:\n                    for key in confusion_matrix.keys():\n                        if key[ 0] == actual and key[ 1] != actual:\n                            confusion_matrix[ key] += 1\n                            #print key\n                            break\n                    #print \"%s\" % node, \n                    #print \"%s\" % validation[ i][ -1]\n                    #print \"Failure\"\n                    break\n            else:                \n                predicted = node\n                confusion_matrix[ (actual, predicted)] += 1\n                break\n    return confusion_matrix", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 13
    }, 
    {
     "cell_type": "markdown", 
     "source": "Decision tree function used to create a binary data set out of a multi-class data set."
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "def Decision_Tree_Learning_Train_Validation_1_vs_Many( training, validation, confusion_matrix, classes):\n\n    attributes = [ i for i in range( 0, len( training[0 ])) ]\n    trees = []\n    not_classes = []\n    for clazz in classes:        \n        data_binary = []\n        not_class = \"not \" + clazz\n        not_classes.append( not_class)\n        for i in range( 0, len( training)):\n            data_binary.append( list( training[ i]))        \n            if data_binary[ i][ -1] != clazz:\n                data_binary[i][ -1] = not_class\n        \n        tree = Decision_Tree_Learning( data_binary, attributes, data_binary)       \n        trees.append( (tree, not_class, clazz)  )        \n        \n    attributes = [ i for i in range( 0, len( training[0 ])) ]    \n \n    for i in range( 1, len( validation)):\n        actual = validation[ i][ -1]\n        predictions = []\n        results = []\n        for tree in trees:            \n            node = tree[ 0]\n            not_class = tree[ 1]\n            clazz = tree[ 2]\n            while True:        \n                if len( node) == 2:\n                    col = node[ 0]\n                    val = node[ 1]\n                    if validation[ i][ col] in val:\n                        node = val[ validation[ i][ col]]\n                    else:\n                        if actual == clazz:                            \n                            predictions.append( not_class)\n                        else:\n                            predictions.append( clazz)\n                        break\n                else:                \n                    predictions.append( node)                    \n                    break\n        #print predictions,\n        for predicted in predictions:\n            if not predicted in not_classes:\n                confusion_matrix[ (actual, predicted)] += 1\n                #print \" -> %s \" % predicted\n                break\n            \n    return confusion_matrix", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 14
    }, 
    {
     "cell_type": "markdown", 
     "source": "Naive Bayes algorithm to create a model."
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "def Naive_Bayes( data):\n    global m, p\n    \n    num_rows = len( data)\n    num_cols = len( data[ 0])\n\n    data_transpose = zip( *data)\n\n    # this makes counting the groups easier\n    #e.g.\n    #              a b c d | e\n    #              k j k o | c\n    # becomes ---> (a,e) (b,e) (c,e) (d,e)\n    #              (k,c) (j,c) (k,c) (o,c)\n    data_class = [ [ ( col, row[ len( row) - 1]) for col in row]  for row in data]\n    data_transpose_class = zip( *data_class)\n\n\n    #data_transpose_counts [0] = \n    #[ Counter({'x': 3656, 'f': 3152, 'k': 828, 'b': 452, 's': 32, 'c': 4}),...\n    data_transpose_counts = []\n    for i in range(0, len( data_transpose)):\n        data_transpose_counts.append( Counter( data_transpose[ i]))\n        #print data_transpose_counts\n\n    #data_transpose_class_counts [0] = \n    #[Counter({('x', 'e'): 1948, ('x', 'p'): 1708, ('f', 'e'): 1596, ('f', 'p'): 1556, ('k', 'p'): 600, ('b', 'e'): 404, \n    data_transpose_class_counts = []\n    for i in range( 0, len( data_transpose_class)):\n        counts = Counter( data_transpose_class[ i])\n        data_transpose_class_counts.append( counts)\n        #print data_transpose_class_counts\n    \n    probs = []\n    for row_index in range( 0, len( data_transpose)):\n        vals = set( data_transpose[ row_index])\n        counter = {}\n        for val in vals:\n            for clazz in set( data_transpose[ -1]):                \n                if (len( data_transpose) - 1 == row_index and \n                   (val, clazz) in data_transpose_class_counts[ row_index]):                    \n                    counter[ (val, clazz)] = float( data_transpose_class_counts[ row_index][ (val, clazz)]) / float( num_rows)\n                elif (val, clazz) in data_transpose_class_counts[ row_index]:\n                    counter[ (val, clazz)] = (float( data_transpose_class_counts[ row_index][ ( val, clazz)]) + m * p) / ( float( data_transpose_counts[ -1][ clazz]) + m)\n        probs.append( counter)\n    \n    zero_probs = {}\n    for clazz in data_transpose_counts[ -1]:\n        zero_probs[ clazz] = (m * p) / float (data_transpose_counts[ -1][ clazz] + m)\n    #print probs\n    return [zero_probs, probs]", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 15
    }, 
    {
     "cell_type": "markdown", 
     "source": "Function to create model and test against the validation data set."
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "def Naive_Bayes_Train_Validate( training, validation, confusion_matrix, classes):\n    \n    nb_result = Naive_Bayes( training)\n    \n    nb_zero_probs = nb_result[ 0]\n    nb_probs = nb_result[ 1]\n    \n    for row in validation:\n        probs = {}\n        for clazz in classes:\n            vals = []\n            for col_index in range( 0, len( row)-1):\n                if (row[ col_index] != \"?\"):\n                    if ( row[ col_index], clazz) in nb_probs[ col_index]:\n                        vals.append( nb_probs[ col_index][ ( row[ col_index], clazz)])\n                    else:\n                        vals.append( nb_zero_probs[ clazz])\n            probs[ clazz] = nb_probs[ -1][ (clazz, clazz)] * product( vals)\n        max_val = max( probs.values())\n        result = [ clazz for clazz in probs.keys() if probs[ clazz] == max_val]\n        result = result[ 0]\n        \n        actual = row[ -1]\n        predicted = result\n        confusion_matrix[ ( actual, predicted)] += 1\n       \n    return confusion_matrix        ", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 16
    }, 
    {
     "cell_type": "markdown", 
     "source": "Function to create binary data out of a multi-class data set."
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "def Naive_Bayes_Train_Validate_1_vs_Many( training, validation, confusion_matrix, classes):\n    binary_classes = []\n    for clazz in classes:        \n        data_binary = []\n        not_class = \"not \" + clazz\n        for i in range( 0, len( training)):\n            data_binary.append( list( training[ i]))        \n            if data_binary[ i][ -1] != clazz:\n                data_binary[i][ -1] = not_class\n        nb_result = Naive_Bayes( data_binary)\n    \n        nb_zero_probs = nb_result[ 0]\n        nb_probs = nb_result[ 1]\n        \n        binary_classes.append( (clazz, nb_probs, nb_zero_probs) )\n                      \n    for row in validation:\n        probs = {}        \n        for binary_class in binary_classes:\n            \n            clazz = binary_class[ 0]\n            nb_probs = binary_class[ 1]\n            nb_zero_probs = binary_class[ 2]\n            \n            vals = []\n            for col_index in range( 0, len( row)-1):\n                if (row[ col_index] != \"?\"):\n                    if ( row[ col_index], clazz) in nb_probs[ col_index]:\n                        vals.append( nb_probs[ col_index][ ( row[ col_index], clazz)])\n                    else:\n                        vals.append( nb_zero_probs[ clazz])\n            probs[ clazz] = nb_probs[ -1][ (clazz, clazz)] * product( vals)\n        max_val = max( probs.values())\n        result = [ clazz for clazz in probs.keys() if probs[ clazz] == max_val]\n        result = result[ 0]        \n        actual = row[ -1]\n        predicted = result\n        confusion_matrix[ (actual, predicted)] += 1\n       \n    return confusion_matrix        ", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 17
    }, 
    {
     "cell_type": "markdown", 
     "source": "Function to run algorithm and generate learning curve data."
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": "def learning_curve(title, data, algorithm, measure_accuracy, arg1, arg2):\n    data_transpose = zip( *data)    \n    classes = set( data_transpose[ -1])\n\n    if len( data) % 10 == 0:\n        step = len( data) / 10\n        folds = range( 0, len( data), step)\n        folds.append( len( data))\n\n    else:\n        step = len( data) / 10\n        folds = range( 0, len( data), step)\n        folds[ -1] = len( data)\n\n    #print \"data count # %s\" % len( data) \n    #print \"step %s \" % step\n    #print folds\n    #print \"fold length %s \" % len( folds)\n    \n    training = []\n\n    confusion_matrix = initialize_confusion_matrix( classes)\n    validation = data[ folds[ 8]: folds[ 9]  ]\n    results =  []\n\n    for i in range( 2, 101, 2):\n        #print \"percent = %i\" % i\n        confusion_matrix = initialize_confusion_matrix( classes)\n        count = 0\n        for j in range(1, 5):\n            count += 1\n            end = int((     float( folds[ 8]) - 1  )   *    float( i) * .01) \n            start = int( (folds[ 8] - 1 - end) * rand())\n            end = start + end\n            training = data[ start: end] \n            confusion_matrix = algorithm( training, validation, confusion_matrix, classes)\n        for key in confusion_matrix.keys():\n            confusion_matrix[ key] = float( confusion_matrix[ key]) / float( count)\n\n        accuracy_result = measure_accuracy( confusion_matrix, arg1, arg2)\n        results.append( (end - start, accuracy_result))\n    \n    accuracy_result = results[0][1]\n    header = \"\"\n    for key in accuracy_result.keys():\n        header += \"<td>%s</td>\" % key\n    html = \"<table>\"\n    html += \"<tr> <td colspan=\"\"%s\"\"> %s </td> </tr>\" % ( str( len( accuracy_result) + 1), title)\n    html += \"<tr> <td>Training Set Size</td> %s </tr>\" % header\n    for result in results:\n        val = \"\"\n        accuracy_result = result[ 1] \n        for key in accuracy_result.keys():\n            val += \"<td>%s</td>\" % accuracy_result[ key]\n        val = \"<td>\" + str( result[0]) + \"</td>\" + val\n        html += \"<tr>%s</tr>\" % val\n    html += \"</table>\"\n    display_html( html, raw=True)\n        ", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 18
    }, 
    {
     "cell_type": "markdown", 
     "source": "Function to run the model and return metrics for comparison."
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "def run_model( title, data, algorithm, measure_accuracy, arg1, arg2):\n    data_transpose = zip( *data)    \n    classes = set( data_transpose[ -1])\n\n    if len( data) % 10 == 0:\n        step = len( data) / 10\n        folds = range( 0, len( data), step)\n        folds.append( len( data))\n\n    else:\n        step = len( data) / 10\n        folds = range( 0, len( data), step)\n        folds[ -1] = len( data)\n    \n    #print folds\n    \n    buckets = []\n    for i in range( 0, len( folds) -1):\n        buckets.append( ( folds[ i], folds[ i + 1]))\n    \n    confusion_matrix = initialize_confusion_matrix( classes)    \n    results =  []\n    count = 0\n    for i in range(0, 9):\n        count += 1\n        buckets[ 8], buckets[ 8 - i] = buckets[ 8 - i], buckets[ 8]    \n        \n        start = buckets[ 8][ 0]\n        end = buckets[ 8][ 1]\n        validation = data[ start: end]       \n        \n        training = []    \n        for j in range( 0, 7):\n            start = buckets[ j][ 0]\n            end = buckets[ j][ 1]\n            training += data[ start: end]    \n        #print buckets\n        \n        confusion_matrix = algorithm( training, validation, confusion_matrix, classes)\n    \n    for key in confusion_matrix.keys():\n            confusion_matrix[ key] = float( confusion_matrix[ key]) / float( count)\n            \n    accuracy_result = measure_accuracy( confusion_matrix, arg1, arg2)\n    results.append( (len( training), accuracy_result))\n\n    html = \"<table>\"\n    html += \"<tr> <td colspan=\"\"2\"\"> %s </td> </tr>\" % title\n    html += \"<tr> <td>Training Set Size</td> <td>Proportion Correct On Test Set </td> </tr>\"\n    for result in results:\n        html += \"<tr> <td>%s</td> <td>%s</td> </tr>\" % tuple( result)\n    html += \"</table>\"\n    display_html( html, raw=True)\n    \n    return results[ 0][ 1]", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 19
    }, 
    {
     "cell_type": "markdown", 
     "source": "Function to run the best model against the test data-set to gerenate the generalization error."
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "def run_best_model( title, data, algorithm, measure_accuracy, arg1, arg2):\n    \n    data_transpose = zip( *data)    \n    classes = set( data_transpose[ -1])\n\n    if len( data) % 10 == 0:\n        step = len( data) / 10\n        folds = range( 0, len( data), step)\n        folds.append( len( data))\n\n    else:\n        step = len( data) / 10\n        folds = range( 0, len( data), step)\n        folds[ -1] = len( data)\n \n    #print folds\n    \n    start = folds[ 0]\n    end = folds[ 9]\n    training = data[ start: end]    \n \n    start = folds[ 9]\n    end = folds[ 10]\n    validation = data[ start: end]\n    \n    confusion_matrix = initialize_confusion_matrix( classes)    \n    \n    confusion_matrix = algorithm( training, validation, confusion_matrix, classes)\n        \n    accuracy_result = measure_accuracy( confusion_matrix, arg1, arg2)\n    results = []\n    results.append( (len( training), accuracy_result))\n    \n    html = \"<table>\"\n    html += \"<tr> <td colspan=\"\"2\"\"> %s </td> </tr>\" % title\n    html += \"<tr> <td>Training Set Size</td> <td>Proportion Correct On Test Set </td> </tr>\"\n    for result in results:\n        html += \"<tr> <td>%s</td> <td>%s</td> </tr>\" % tuple( result)\n    html += \"</table>\"\n    display_html( html, raw=True)\n    \n    return results[ 0][ 1]", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 20
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": "#data_mushroom = get_data('/Users/Hassani_A/Desktop/Classes/AI/prj3/mushroom.csv')\ndata_mushroom = get_data('/Users/Lauren/Desktop/PR3/mushroom.csv')\n#data_nursery = get_data('/Users/Hassani_A/Desktop/Classes/AI/prj3/nursery.csv')\ndata_nursery = get_data('/Users/Lauren/Desktop/PR3/nursery.csv')\n\n#print len( data_mushroom)\n#print len( data_nursery)\n\nlearning_curve (\"Learning Curve Mushroom - Naive Bayes\", data_mushroom, Naive_Bayes_Train_Validate, get_binary_stats, 'e', 'p')\nlearning_curve (\"Learning Curve Mushroom - Decision Tree\", data_mushroom, Decision_Tree_Learning_Train_Validation, get_binary_stats, 'e', 'p')\n\nlearning_curve (\"Learning Curve Nursery - Naive Bayes\", data_nursery, Naive_Bayes_Train_Validate, get_multi_class_stats, '', '')\nlearning_curve (\"Learning Curve Nursery - Decision Tree\", data_nursery, Decision_Tree_Learning_Train_Validation, get_multi_class_stats, '', '')\n\nmushroom_naive_bayes = run_model (\"Mushroom - Naive Bayes\", data_mushroom, Naive_Bayes_Train_Validate, get_fscore, 'e', 'p')\nmushroom_decision_tree = run_model (\"Mushroom - Decision Tree\", data_mushroom, Decision_Tree_Learning_Train_Validation, get_fscore, 'e', 'p')\n\nif mushroom_naive_bayes > mushroom_decision_tree:\n    run_best_model (\"Best Model - Mushroom - Naive Bayes\", data_mushroom, Naive_Bayes_Train_Validate, get_fscore, 'e', 'p')\nelse:\n    run_best_model (\"Best Model - Mushroom - Decision Tree\", data_mushroom, Decision_Tree_Learning_Train_Validation, get_fscore, 'e', 'p')\n    \nnursery_naive_bayes = run_model (\"Nursery - Naive Bayes\", data_nursery, Naive_Bayes_Train_Validate, get_accuracy, '', '')\nnursery_decision_Tree = run_model (\"Nursery - Decision Tree\", data_nursery, Decision_Tree_Learning_Train_Validation, get_accuracy, '', '')\n\nif nursery_naive_bayes > nursery_decision_Tree:\n    run_best_model (\"Best Model - Nursery - Naive Bayes\", data_nursery, Naive_Bayes_Train_Validate, get_accuracy, '', '')\nelse:\n    run_best_model(\"Best Model - Nursery - Decision Tree\", data_nursery, Decision_Tree_Learning_Train_Validation, get_accuracy, '', '')\n\n\nrun_model (\"Nursery 1 vs Many - Naive Bayes\"  , data_nursery, Naive_Bayes_Train_Validate_1_vs_Many,              get_accuracy, '', '') \nrun_model (\"Nursery 1 vs Many - Decision Tree\", data_nursery, Decision_Tree_Learning_Train_Validation_1_vs_Many, get_accuracy, '', '') ", 
     "language": "python", 
     "outputs": [
      {
       "html": "<table><tr> <td colspan=4> Learning Curve Mushroom - Naive Bayes </td> </tr><tr> <td>Training Set Size</td> <td>recall</td><td>precision</td><td>fscore</td> </tr><tr><td>129</td><td>0.978183962264</td><td>0.956195965418</td><td>0.967064995628</td></tr><tr><td>259</td><td>0.984080188679</td><td>0.969221835075</td><td>0.976594499707</td></tr><tr><td>389</td><td>0.991155660377</td><td>0.97505800464</td><td>0.983040935673</td></tr><tr><td>519</td><td>0.995872641509</td><td>0.972926267281</td><td>0.984265734266</td></tr><tr><td>649</td><td>0.994103773585</td><td>0.983090379009</td><td>0.988566402814</td></tr><tr><td>779</td><td>0.998231132075</td><td>0.975230414747</td><td>0.986596736597</td></tr><tr><td>909</td><td>0.994693396226</td><td>0.983673469388</td><td>0.989152741132</td></tr><tr><td>1039</td><td>0.995872641509</td><td>0.984839650146</td><td>0.990325417766</td></tr><tr><td>1169</td><td>0.994103773585</td><td>0.984813084112</td><td>0.989436619718</td></tr><tr><td>1299</td><td>0.993514150943</td><td>0.984228971963</td><td>0.988849765258</td></tr><tr><td>1428</td><td>0.995872641509</td><td>0.984265734266</td><td>0.990035169988</td></tr><tr><td>1558</td><td>0.99233490566</td><td>0.98478642481</td><td>0.988546255507</td></tr><tr><td>1688</td><td>0.995872641509</td><td>0.985414235706</td><td>0.990615835777</td></tr><tr><td>1818</td><td>0.995283018868</td><td>0.984830805134</td><td>0.990029325513</td></tr><tr><td>1948</td><td>0.995283018868</td><td>0.984256559767</td><td>0.989739079449</td></tr><tr><td>2078</td><td>0.996462264151</td><td>0.984274898078</td><td>0.99033108702</td></tr><tr><td>2208</td><td>0.994693396226</td><td>0.985397196262</td><td>0.990023474178</td></tr><tr><td>2338</td><td>0.996462264151</td><td>0.984274898078</td><td>0.99033108702</td></tr><tr><td>2468</td><td>0.992924528302</td><td>0.985371562317</td><td>0.989133627019</td></tr><tr><td>2598</td><td>0.995872641509</td><td>0.985414235706</td><td>0.990615835777</td></tr><tr><td>2727</td><td>0.995872641509</td><td>0.985989492119</td><td>0.990906424171</td></tr><tr><td>2857</td><td>0.995283018868</td><td>0.984830805134</td><td>0.990029325513</td></tr><tr><td>2987</td><td>0.996462264151</td><td>0.985422740525</td><td>0.990911756083</td></tr><tr><td>3117</td><td>0.996462264151</td><td>0.985997666278</td><td>0.991202346041</td></tr><tr><td>3247</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>3377</td><td>0.995872641509</td><td>0.985989492119</td><td>0.990906424171</td></tr><tr><td>3507</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>3637</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>3767</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>3897</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>4026</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>4156</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>4286</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>4416</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>4546</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>4676</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>4806</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>4936</td><td>0.995283018868</td><td>0.986557568673</td><td>0.990901085999</td></tr><tr><td>5066</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>5196</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>5325</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>5455</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>5585</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>5715</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>5845</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>5975</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>6105</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>6235</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>6365</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr><tr><td>6495</td><td>0.995283018868</td><td>0.985981308411</td><td>0.990610328638</td></tr></table>", 
       "output_type": "display_data"
      }, 
      {
       "html": "<table><tr> <td colspan=4> Learning Curve Mushroom - Decision Tree </td> </tr><tr> <td>Training Set Size</td> <td>recall</td><td>precision</td><td>fscore</td> </tr><tr><td>129</td><td>0.976359338061</td><td>0.978093546477</td><td>0.977225672878</td></tr><tr><td>259</td><td>0.987588652482</td><td>0.991103202847</td><td>0.989342806394</td></tr><tr><td>389</td><td>0.998817966903</td><td>0.991202346041</td><td>0.994995584339</td></tr><tr><td>519</td><td>0.999408983452</td><td>0.997051886792</td><td>0.998229043684</td></tr><tr><td>649</td><td>0.997044917258</td><td>0.989442815249</td><td>0.993229319988</td></tr><tr><td>779</td><td>0.998817966903</td><td>0.994117647059</td><td>0.996462264151</td></tr><tr><td>909</td><td>0.998226950355</td><td>0.996460176991</td><td>0.997342781222</td></tr><tr><td>1039</td><td>0.997635933806</td><td>0.997635933806</td><td>0.997635933806</td></tr><tr><td>1169</td><td>0.998226950355</td><td>0.996460176991</td><td>0.997342781222</td></tr><tr><td>1299</td><td>0.997635933806</td><td>0.997046662729</td><td>0.997341211226</td></tr><tr><td>1428</td><td>1.0</td><td>0.999409332546</td><td>0.999704579025</td></tr><tr><td>1558</td><td>0.999408983452</td><td>0.997640117994</td><td>0.998523767346</td></tr><tr><td>1688</td><td>1.0</td><td>0.998230088496</td><td>0.999114260407</td></tr><tr><td>1818</td><td>1.0</td><td>0.998230088496</td><td>0.999114260407</td></tr><tr><td>1948</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>2078</td><td>1.0</td><td>0.996466431095</td><td>0.998230088496</td></tr><tr><td>2208</td><td>1.0</td><td>0.998230088496</td><td>0.999114260407</td></tr><tr><td>2338</td><td>1.0</td><td>0.997641509434</td><td>0.998819362456</td></tr><tr><td>2468</td><td>1.0</td><td>0.998819362456</td><td>0.999409332546</td></tr><tr><td>2598</td><td>1.0</td><td>0.998819362456</td><td>0.999409332546</td></tr><tr><td>2727</td><td>1.0</td><td>0.997641509434</td><td>0.998819362456</td></tr><tr><td>2857</td><td>1.0</td><td>0.998819362456</td><td>0.999409332546</td></tr><tr><td>2987</td><td>1.0</td><td>0.997641509434</td><td>0.998819362456</td></tr><tr><td>3117</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>3247</td><td>1.0</td><td>0.998819362456</td><td>0.999409332546</td></tr><tr><td>3377</td><td>1.0</td><td>0.998819362456</td><td>0.999409332546</td></tr><tr><td>3507</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>3637</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>3767</td><td>1.0</td><td>0.998819362456</td><td>0.999409332546</td></tr><tr><td>3897</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>4026</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>4156</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>4286</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>4416</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>4546</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>4676</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>4806</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>4936</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>5066</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>5196</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>5325</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>5455</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>5585</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>5715</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>5845</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>5975</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>6105</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>6235</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>6365</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>6495</td><td>1.0</td><td>1.0</td><td>1.0</td></tr></table>", 
       "output_type": "display_data"
      }, 
      {
       "html": "<table><tr> <td colspan=2> Learning Curve Nursery - Naive Bayes </td> </tr><tr> <td>Training Set Size</td> <td>accuracy</td> </tr><tr><td>207</td><td>0.883487654321</td></tr><tr><td>414</td><td>0.905671296296</td></tr><tr><td>622</td><td>0.914158950617</td></tr><tr><td>829</td><td>0.911265432099</td></tr><tr><td>1036</td><td>0.913966049383</td></tr><tr><td>1244</td><td>0.912037037037</td></tr><tr><td>1451</td><td>0.913966049383</td></tr><tr><td>1658</td><td>0.908757716049</td></tr><tr><td>1866</td><td>0.913580246914</td></tr><tr><td>2073</td><td>0.91512345679</td></tr><tr><td>2280</td><td>0.912037037037</td></tr><tr><td>2488</td><td>0.917052469136</td></tr><tr><td>2695</td><td>0.919174382716</td></tr><tr><td>2902</td><td>0.920524691358</td></tr><tr><td>3110</td><td>0.918981481481</td></tr><tr><td>3317</td><td>0.920717592593</td></tr><tr><td>3524</td><td>0.917438271605</td></tr><tr><td>3732</td><td>0.920138888889</td></tr><tr><td>3939</td><td>0.918981481481</td></tr><tr><td>4146</td><td>0.919560185185</td></tr><tr><td>4354</td><td>0.919367283951</td></tr><tr><td>4561</td><td>0.919174382716</td></tr><tr><td>4768</td><td>0.920138888889</td></tr><tr><td>4976</td><td>0.921875</td></tr><tr><td>5183</td><td>0.920524691358</td></tr><tr><td>5390</td><td>0.918788580247</td></tr><tr><td>5598</td><td>0.918788580247</td></tr><tr><td>5805</td><td>0.918402777778</td></tr><tr><td>6012</td><td>0.921103395062</td></tr><tr><td>6220</td><td>0.91763117284</td></tr><tr><td>6427</td><td>0.916859567901</td></tr><tr><td>6634</td><td>0.919560185185</td></tr><tr><td>6842</td><td>0.921296296296</td></tr><tr><td>7049</td><td>0.919560185185</td></tr><tr><td>7256</td><td>0.920717592593</td></tr><tr><td>7464</td><td>0.919560185185</td></tr><tr><td>7671</td><td>0.920138888889</td></tr><tr><td>7878</td><td>0.920910493827</td></tr><tr><td>8086</td><td>0.918981481481</td></tr><tr><td>8293</td><td>0.919174382716</td></tr><tr><td>8500</td><td>0.920910493827</td></tr><tr><td>8708</td><td>0.920524691358</td></tr><tr><td>8915</td><td>0.919560185185</td></tr><tr><td>9122</td><td>0.917824074074</td></tr><tr><td>9330</td><td>0.919367283951</td></tr><tr><td>9537</td><td>0.919945987654</td></tr><tr><td>9744</td><td>0.920138888889</td></tr><tr><td>9952</td><td>0.920717592593</td></tr><tr><td>10159</td><td>0.920717592593</td></tr><tr><td>10367</td><td>0.922839506173</td></tr></table>", 
       "output_type": "display_data"
      }, 
      {
       "html": "<table><tr> <td colspan=2> Learning Curve Nursery - Decision Tree </td> </tr><tr> <td>Training Set Size</td> <td>accuracy</td> </tr><tr><td>207</td><td>0.823938223938</td></tr><tr><td>414</td><td>0.874131274131</td></tr><tr><td>622</td><td>0.898841698842</td></tr><tr><td>829</td><td>0.909845559846</td></tr><tr><td>1036</td><td>0.914092664093</td></tr><tr><td>1244</td><td>0.917953667954</td></tr><tr><td>1451</td><td>0.925675675676</td></tr><tr><td>1658</td><td>0.92972972973</td></tr><tr><td>1866</td><td>0.936486486486</td></tr><tr><td>2073</td><td>0.933590733591</td></tr><tr><td>2280</td><td>0.939382239382</td></tr><tr><td>2488</td><td>0.948648648649</td></tr><tr><td>2695</td><td>0.943629343629</td></tr><tr><td>2902</td><td>0.943822393822</td></tr><tr><td>3110</td><td>0.953861003861</td></tr><tr><td>3317</td><td>0.951158301158</td></tr><tr><td>3524</td><td>0.949420849421</td></tr><tr><td>3732</td><td>0.954633204633</td></tr><tr><td>3939</td><td>0.959652509653</td></tr><tr><td>4146</td><td>0.956177606178</td></tr><tr><td>4354</td><td>0.962741312741</td></tr><tr><td>4561</td><td>0.961583011583</td></tr><tr><td>4768</td><td>0.964671814672</td></tr><tr><td>4976</td><td>0.966988416988</td></tr><tr><td>5183</td><td>0.961003861004</td></tr><tr><td>5390</td><td>0.966795366795</td></tr><tr><td>5598</td><td>0.965444015444</td></tr><tr><td>5805</td><td>0.967953667954</td></tr><tr><td>6012</td><td>0.966409266409</td></tr><tr><td>6220</td><td>0.971235521236</td></tr><tr><td>6427</td><td>0.971042471042</td></tr><tr><td>6634</td><td>0.970077220077</td></tr><tr><td>6842</td><td>0.97528957529</td></tr><tr><td>7049</td><td>0.971235521236</td></tr><tr><td>7256</td><td>0.968532818533</td></tr><tr><td>7464</td><td>0.974517374517</td></tr><tr><td>7671</td><td>0.973745173745</td></tr><tr><td>7878</td><td>0.97528957529</td></tr><tr><td>8086</td><td>0.97471042471</td></tr><tr><td>8293</td><td>0.975096525097</td></tr><tr><td>8500</td><td>0.975096525097</td></tr><tr><td>8708</td><td>0.976254826255</td></tr><tr><td>8915</td><td>0.976833976834</td></tr><tr><td>9122</td><td>0.976640926641</td></tr><tr><td>9330</td><td>0.978764478764</td></tr><tr><td>9537</td><td>0.978764478764</td></tr><tr><td>9744</td><td>0.980308880309</td></tr><tr><td>9952</td><td>0.980888030888</td></tr><tr><td>10159</td><td>0.982432432432</td></tr><tr><td>10367</td><td>0.983011583012</td></tr></table>", 
       "output_type": "display_data"
      }, 
      {
       "html": "<table><tr> <td colspan=2> Mushroom - Naive Bayes </td> </tr><tr> <td>Training Set Size</td> <td>Proportion Correct On Test Set </td> </tr><tr> <td>5684</td> <td>0.992894736842</td> </tr></table>", 
       "output_type": "display_data"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "812.0\n811.0"
      }, 
      {
       "html": "<table><tr> <td colspan=2> Mushroom - Decision Tree </td> </tr><tr> <td>Training Set Size</td> <td>Proportion Correct On Test Set </td> </tr><tr> <td>5684</td> <td>1.0</td> </tr></table>", 
       "output_type": "display_data"
      }, 
      {
       "html": "<table><tr> <td colspan=2> Best Model - Mushroom - Decision Tree </td> </tr><tr> <td>Training Set Size</td> <td>Proportion Correct On Test Set </td> </tr><tr> <td>7308</td> <td>1.0</td> </tr></table>", 
       "output_type": "display_data"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n1296.0"
      }, 
      {
       "html": "<table><tr> <td colspan=2> Nursery - Naive Bayes </td> </tr><tr> <td>Training Set Size</td> <td>Proportion Correct On Test Set </td> </tr><tr> <td>9072</td> <td>0.929783950617</td> </tr></table>", 
       "output_type": "display_data"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n1295.0"
      }, 
      {
       "html": "<table><tr> <td colspan=2> Nursery - Decision Tree </td> </tr><tr> <td>Training Set Size</td> <td>Proportion Correct On Test Set </td> </tr><tr> <td>9072</td> <td>0.985070785071</td> </tr></table>", 
       "output_type": "display_data"
      }, 
      {
       "html": "<table><tr> <td colspan=2> Best Model - Nursery - Decision Tree </td> </tr><tr> <td>Training Set Size</td> <td>Proportion Correct On Test Set </td> </tr><tr> <td>11664</td> <td>0.989189189189</td> </tr></table>", 
       "output_type": "display_data"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n1296.0"
      }, 
      {
       "html": "<table><tr> <td colspan=2> Nursery 1 vs Many - Naive Bayes </td> </tr><tr> <td>Training Set Size</td> <td>Proportion Correct On Test Set </td> </tr><tr> <td>9072</td> <td>0.929783950617</td> </tr></table>", 
       "output_type": "display_data"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n1295.0"
      }, 
      {
       "html": "<table><tr> <td colspan=2> Nursery 1 vs Many - Decision Tree </td> </tr><tr> <td>Training Set Size</td> <td>Proportion Correct On Test Set </td> </tr><tr> <td>9072</td> <td>0.985070785071</td> </tr></table>", 
       "output_type": "display_data"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": ""
      }, 
      {
       "output_type": "pyout", 
       "prompt_number": 21, 
       "text": "0.9850707850707852"
      }
     ], 
     "prompt_number": 21
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 21
    }
   ]
  }
 ]
}